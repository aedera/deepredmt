{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_deepredmt_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67nIBmLuADgd"
      },
      "source": [
        "# Train Deepred-Mt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5SoJ3dUAIAp"
      },
      "source": [
        "## Install Deepred-Mt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAYSa6Ld99i5",
        "outputId": "524914a7-142b-434c-bb98-facd117964e8"
      },
      "source": [
        "!pip install -U \"deepredmt @ git+https://github.com/aedera/deepredmt.git\" > /dev/null"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/aedera/deepredmt.git /tmp/pip-install-otgctr2p/deepredmt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PWdZ8ylBhBP"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHCZ_ih8Bj2F"
      },
      "source": [
        "import tensorflow as tf\n",
        "import deepredmt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05qhFT0lAJyh"
      },
      "source": [
        "## Prepare training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yRLsFWKDVBa"
      },
      "source": [
        "As training dataset, we will use a subset of the training data originally employed to train Deepred-Mt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwbPSe1M-TO2",
        "outputId": "d5d9bc0e-b924-47a8-ccf5-a438c17ebb5d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/aedera/deepredmt/main/data/training-data.tsv.gz"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-22 19:47:05--  https://raw.githubusercontent.com/aedera/deepredmt/main/data/training-data.tsv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3026591 (2.9M) [application/octet-stream]\n",
            "Saving to: ‘training-data.tsv.gz’\n",
            "\n",
            "training-data.tsv.g 100%[===================>]   2.89M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-04-22 19:47:06 (20.1 MB/s) - ‘training-data.tsv.gz’ saved [3026591/3026591]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7CQhy-EDpVw"
      },
      "source": [
        "The following commands process the downloaded data to change the format, into the one expected by the learning method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFOGhLKk-Xb9",
        "outputId": "8c02c299-c369-423c-cbde-1cb985e67762"
      },
      "source": [
        "!gzip -d training-data.tsv.gz\n",
        "!head -10 training-data.tsv | column -t"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Allium_cepa!atp1!1002  atp1!1020  3  GCTTTCCCTGGGGATGTTTT  C  TATTTACATTCCCGTCTCTT  TTC  0.0011  0  0.00\n",
            "Allium_cepa!atp1!1009  atp1!1027  1  CTGGGGATGTTTTCTATTTA  C  ATTCCCGTCTCTTAGAAAGA  CAT  0.0002  0  0.00\n",
            "Allium_cepa!atp1!1013  atp1!1031  2  GGATGTTTTCTATTTACATT  C  CCGTCTCTTAGAAAGAGCCG  TCC  0.0002  0  0.00\n",
            "Allium_cepa!atp1!1014  atp1!1032  3  GATGTTTTCTATTTACATTC  C  CGTCTCTTAGAAAGAGCCGC  TCC  0.0010  0  0.00\n",
            "Allium_cepa!atp1!1015  atp1!1033  1  ATGTTTTCTATTTACATTCC  C  GTCTCTTAGAAAGAGCCGCT  CGT  0.0000  0  0.00\n",
            "Allium_cepa!atp1!1018  atp1!1036  1  TTTTCTATTTACATTCCCGT  C  TCTTAGAAAGAGCCGCTAAA  CTC  0.0002  0  0.00\n",
            "Allium_cepa!atp1!1020  atp1!1038  3  TTCTATTTACATTCCCGTCT  C  TTAGAAAGAGCCGCTAAACG  CTC  0.0018  0  0.00\n",
            "Allium_cepa!atp1!1031  atp1!1049  2  TTCCCGTCTCTTAGAAAGAG  C  CGCTAAACGATCGGACCAGA  GCC  0.0000  0  0.00\n",
            "Allium_cepa!atp1!1032  atp1!1050  3  TCCCGTCTCTTAGAAAGAGC  C  GCTAAACGATCGGACCAGAC  GCC  0.0000  0  0.00\n",
            "Allium_cepa!atp1!1034  atp1!1052  2  CCGTCTCTTAGAAAGAGCCG  C  TAAACGATCGGACCAGACAG  GCT  0.0000  0  0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ5-MAEY-oRE",
        "outputId": "79d33369-04cc-4a67-adff-0eb4504d5f85"
      },
      "source": [
        "!cut -f4,5,6,8,9 training-data.tsv | \\\n",
        "  awk '{{printf \"%s%s%s\\t%s\\t%s\\n\", $$1, $$2, $$3, $$5, $$4}}' > trainset.tmp\n",
        "\n",
        "# nucleotide window, label (0/1), and editing extent\n",
        "!head -10 trainset.tmp | column -t"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GCTTTCCCTGGGGATGTTTTCTATTTACATTCCCGTCTCTT  0  0.0011\n",
            "CTGGGGATGTTTTCTATTTACATTCCCGTCTCTTAGAAAGA  0  0.0002\n",
            "GGATGTTTTCTATTTACATTCCCGTCTCTTAGAAAGAGCCG  0  0.0002\n",
            "GATGTTTTCTATTTACATTCCCGTCTCTTAGAAAGAGCCGC  0  0.0010\n",
            "ATGTTTTCTATTTACATTCCCGTCTCTTAGAAAGAGCCGCT  0  0.0000\n",
            "TTTTCTATTTACATTCCCGTCTCTTAGAAAGAGCCGCTAAA  0  0.0002\n",
            "TTCTATTTACATTCCCGTCTCTTAGAAAGAGCCGCTAAACG  0  0.0018\n",
            "TTCCCGTCTCTTAGAAAGAGCCGCTAAACGATCGGACCAGA  0  0.0000\n",
            "TCCCGTCTCTTAGAAAGAGCCGCTAAACGATCGGACCAGAC  0  0.0000\n",
            "CCGTCTCTTAGAAAGAGCCGCTAAACGATCGGACCAGACAG  0  0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAGEbNlvDltQ"
      },
      "source": [
        "Take a sample of 1000 datapoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qxb6Z5j_uKe"
      },
      "source": [
        "!shuf trainset.tmp | head -1000 > trainset.tsv "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP5lrXPvANfR"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfv-o4dz9prI",
        "outputId": "4ebd16f1-9645-42d1-fc87-9e63e556c1e2"
      },
      "source": [
        "deepredmt.fit(\"trainset.tsv\", batch_size=32, epochs=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_16 (Batc (None, 41, 4)             16        \n",
            "_________________________________________________________________\n",
            "conv1d_0_0 (Conv1D)          (None, 41, 16)            208       \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 41, 16)            64        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 41, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_0_1 (Conv1D)          (None, 41, 16)            784       \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 41, 16)            64        \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 41, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_0_2 (Conv1D)          (None, 41, 16)            784       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 41, 16)            64        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 41, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 41, 16)            784       \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 41, 16)            64        \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 41, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 21, 32)            1568      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 21, 32)            128       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 21, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 11, 64)            6208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 11, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 11, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 6, 128)            24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 6, 128)            512       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 3, 256)            98560     \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 3, 256)            1024      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 2, 512)            393728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 2, 512)            2048      \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 2, 512)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "embedder (Dense)             (None, 5)                 5125      \n",
            "=================================================================\n",
            "Total params: 536,693\n",
            "Trainable params: 534,573\n",
            "Non-trainable params: 2,120\n",
            "_________________________________________________________________\n",
            "Model: \"deepredmt\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 41, 4)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Sequential)            (None, 5)            536693      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            12          encoder[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            3           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 41, 4)        459396      encoder[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cla (Activation)                (None, 1)            0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 996,104\n",
            "Trainable params: 992,728\n",
            "Non-trainable params: 3,376\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            " 6/19 [========>.....................] - ETA: 3s - loss: 2.1380 - decoder_loss: 1.6740 - cla_loss: 0.8351 - cla_1_loss: 0.4659 - cla_precision_1: 0.5329 - cla_recall_1: 0.5139 - cla_mean_squared_error: 0.2844WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1031s vs `on_train_batch_end` time: 0.1266s). Check your callbacks.\n",
            "19/19 [==============================] - 12s 234ms/step - loss: 2.1103 - decoder_loss: 1.6063 - cla_loss: 0.8523 - cla_1_loss: 0.4548 - cla_precision_1: 0.5458 - cla_recall_1: 0.5417 - cla_mean_squared_error: 0.2851 - val_loss: 2.0719 - val_decoder_loss: 1.7310 - val_cla_loss: 0.7185 - val_cla_1_loss: 0.4879 - val_cla_precision_1: 0.4865 - val_cla_recall_1: 0.8438 - val_cla_mean_squared_error: 0.2569\n",
            "\n",
            "Checkpointing weights val_loss= 2.0719\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 2s 125ms/step - loss: 1.5685 - decoder_loss: 1.4014 - cla_loss: 0.5651 - cla_1_loss: 0.3027 - cla_precision_1: 0.7389 - cla_recall_1: 0.7463 - cla_mean_squared_error: 0.1778 - val_loss: 1.9298 - val_decoder_loss: 1.5537 - val_cla_loss: 0.6843 - val_cla_1_loss: 0.4687 - val_cla_precision_1: 0.5229 - val_cla_recall_1: 0.8906 - val_cla_mean_squared_error: 0.2424\n",
            "\n",
            "Checkpointing weights val_loss= 1.9298\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 2s 123ms/step - loss: 1.3853 - decoder_loss: 1.3612 - cla_loss: 0.4608 - cla_1_loss: 0.2439 - cla_precision_1: 0.8003 - cla_recall_1: 0.7895 - cla_mean_squared_error: 0.1419 - val_loss: 1.8078 - val_decoder_loss: 1.4465 - val_cla_loss: 0.6412 - val_cla_1_loss: 0.4433 - val_cla_precision_1: 0.5957 - val_cla_recall_1: 0.8750 - val_cla_mean_squared_error: 0.2196\n",
            "\n",
            "Checkpointing weights val_loss= 1.8078\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 2s 125ms/step - loss: 1.3246 - decoder_loss: 1.3513 - cla_loss: 0.4215 - cla_1_loss: 0.2274 - cla_precision_1: 0.8025 - cla_recall_1: 0.8237 - cla_mean_squared_error: 0.1232 - val_loss: 1.7026 - val_decoder_loss: 1.3939 - val_cla_loss: 0.5942 - val_cla_1_loss: 0.4115 - val_cla_precision_1: 0.6146 - val_cla_recall_1: 0.9219 - val_cla_mean_squared_error: 0.2032\n",
            "\n",
            "Checkpointing weights val_loss= 1.7026\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 2s 123ms/step - loss: 1.2138 - decoder_loss: 1.3455 - cla_loss: 0.3381 - cla_1_loss: 0.2029 - cla_precision_1: 0.8652 - cla_recall_1: 0.8576 - cla_mean_squared_error: 0.1022 - val_loss: 1.6090 - val_decoder_loss: 1.3733 - val_cla_loss: 0.5450 - val_cla_1_loss: 0.3773 - val_cla_precision_1: 0.6709 - val_cla_recall_1: 0.8281 - val_cla_mean_squared_error: 0.1801\n",
            "\n",
            "Checkpointing weights val_loss= 1.6090\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 2s 125ms/step - loss: 1.2450 - decoder_loss: 1.3363 - cla_loss: 0.3881 - cla_1_loss: 0.1888 - cla_precision_1: 0.8546 - cla_recall_1: 0.8504 - cla_mean_squared_error: 0.1064 - val_loss: 1.5478 - val_decoder_loss: 1.3601 - val_cla_loss: 0.5168 - val_cla_1_loss: 0.3509 - val_cla_precision_1: 0.6744 - val_cla_recall_1: 0.9062 - val_cla_mean_squared_error: 0.1742\n",
            "\n",
            "Checkpointing weights val_loss= 1.5478\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 2s 127ms/step - loss: 1.0516 - decoder_loss: 1.3303 - cla_loss: 0.2448 - cla_1_loss: 0.1416 - cla_precision_1: 0.9033 - cla_recall_1: 0.9123 - cla_mean_squared_error: 0.0676 - val_loss: 1.3983 - val_decoder_loss: 1.3507 - val_cla_loss: 0.4188 - val_cla_1_loss: 0.3041 - val_cla_precision_1: 0.7500 - val_cla_recall_1: 0.9375 - val_cla_mean_squared_error: 0.1402\n",
            "\n",
            "Checkpointing weights val_loss= 1.3983\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 2s 124ms/step - loss: 1.0663 - decoder_loss: 1.3259 - cla_loss: 0.2548 - cla_1_loss: 0.1486 - cla_precision_1: 0.8995 - cla_recall_1: 0.8912 - cla_mean_squared_error: 0.0777 - val_loss: 1.3808 - val_decoder_loss: 1.3449 - val_cla_loss: 0.4346 - val_cla_1_loss: 0.2737 - val_cla_precision_1: 0.8136 - val_cla_recall_1: 0.7500 - val_cla_mean_squared_error: 0.1427\n",
            "\n",
            "Checkpointing weights val_loss= 1.3808\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 2s 124ms/step - loss: 1.0375 - decoder_loss: 1.3256 - cla_loss: 0.2454 - cla_1_loss: 0.1293 - cla_precision_1: 0.9083 - cla_recall_1: 0.8925 - cla_mean_squared_error: 0.0705 - val_loss: 1.3572 - val_decoder_loss: 1.3431 - val_cla_loss: 0.4195 - val_cla_1_loss: 0.2662 - val_cla_precision_1: 0.8448 - val_cla_recall_1: 0.7656 - val_cla_mean_squared_error: 0.1373\n",
            "\n",
            "Checkpointing weights val_loss= 1.3572\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 2s 124ms/step - loss: 0.9097 - decoder_loss: 1.3199 - cla_loss: 0.1418 - cla_1_loss: 0.1080 - cla_precision_1: 0.9386 - cla_recall_1: 0.9559 - cla_mean_squared_error: 0.0528 - val_loss: 1.4134 - val_decoder_loss: 1.3398 - val_cla_loss: 0.4595 - val_cla_1_loss: 0.2841 - val_cla_precision_1: 0.7424 - val_cla_recall_1: 0.7656 - val_cla_mean_squared_error: 0.1539\n",
            "\n",
            "Best val_loss 1.3572\n",
            "INFO:tensorflow:Assets written to: ./models/deepredmt/210422-1947.tf/assets\n",
            "Best model saved.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S7uBjXWBGfQ"
      },
      "source": [
        "The trained model is saved in a tensorflow file in a folder named models/deepredmt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSjJFxRZA_9Y",
        "outputId": "fc9c3e62-83fe-4169-9f2c-051a1c0b3f83"
      },
      "source": [
        "!ls -d ./models/deepredmt/*.tf"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./models/deepredmt/210422-1947.tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqQuFkWpBLNy"
      },
      "source": [
        "We can load this model and use it to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSmysXO-BKfk"
      },
      "source": [
        "path_to_model = !ls -d ./models/deepredmt/*.tf\n",
        "model = tf.keras.models.load_model(path_to_model[0])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7AQGoDZCDpk",
        "outputId": "3747c374-6ff5-4bfe-a99f-5085b768974d"
      },
      "source": [
        "y_pred = deepredmt.predict('trainset.tsv', path_to_model[0])\n",
        "y_pred[0:20] # see the predicted scores for the first 20 windows"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.94932175],\n",
              "       [0.987972  ],\n",
              "       [0.43396324],\n",
              "       [0.72903997],\n",
              "       [0.5498872 ],\n",
              "       [0.55503607],\n",
              "       [0.6339734 ],\n",
              "       [0.7841495 ],\n",
              "       [0.06540111],\n",
              "       [0.52731943],\n",
              "       [0.5952312 ],\n",
              "       [0.8876858 ],\n",
              "       [0.24046293],\n",
              "       [0.02224666],\n",
              "       [0.5677028 ],\n",
              "       [0.1244027 ],\n",
              "       [0.98225266],\n",
              "       [0.39220166],\n",
              "       [0.08878222],\n",
              "       [0.9660412 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}